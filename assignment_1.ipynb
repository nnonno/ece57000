{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"assignment_1.ipynb","provenance":[{"file_id":"1G7_4_j_ulHqt0OPv3XbK6eQmZvCDdA2P","timestamp":1630470420909}],"collapsed_sections":[],"authorship_tag":"ABX9TyMVev0daM5MgGr98T5SSjLY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"nwaLBXs5nBlf","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1630475133951,"user_tz":240,"elapsed":275,"user":{"displayName":"Yifu Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnOnAIqYrrfdQ8fUqr0PeOTkp8J-Q2Z4bfbL1P=s64","userId":"02816651394149968559"}},"outputId":"7c8250c4-26ce-4349-803c-dfce76ee737a"},"source":["from google.colab import drive \n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"t_DrCJvZy-sg"},"source":["## 3. Load data (10/100 points)"]},{"cell_type":"code","metadata":{"id":"QpVvGFfsnTAz","executionInfo":{"status":"ok","timestamp":1630475134442,"user_tz":240,"elapsed":18,"user":{"displayName":"Yifu Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnOnAIqYrrfdQ8fUqr0PeOTkp8J-Q2Z4bfbL1P=s64","userId":"02816651394149968559"}}},"source":["import os                                                                \n","#########################        YOUR CODE        ######################### \n","dir_root = '/content/drive/MyDrive/Colab Notebooks/ece57000/Assignment-1'    \n","#########################      END YOUR CODE      #########################\n","train_dir = os.path.join(dir_root, 'train.txt')   "],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDgW8hQ2ndmD","executionInfo":{"status":"ok","timestamp":1630475134443,"user_tz":240,"elapsed":17,"user":{"displayName":"Yifu Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnOnAIqYrrfdQ8fUqr0PeOTkp8J-Q2Z4bfbL1P=s64","userId":"02816651394149968559"}}},"source":["# use built-in function \"open\" to read files \n","#  and use the \"with\" syntax to automatically close the file after the block\n","with open(train_dir, 'r') as f:\n","    train_lines = f.readlines()\n","\n","# construct two lists to store phrases and labels seperately\n","train_data, train_label = [], []\n","for line in train_lines:\n","    line_sec = line.split(\"|\", -1)\n","    train_data.append(line_sec[0])\n","    train_label.append(int(line_sec[1]))\n","\n","# # preview some data here\n","# preview = 10                 # feel free to toggle this number to see more/less data\n","# for i, (phrase, label) in enumerate(zip(train_data[:preview], train_label[:preview])):\n","#     print(f'Phrase {i:03} \\\"{phrase}\\\" has the sentiment {label}')"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"insG_h_mzBYn"},"source":["## 4. Classifier (80/100 points)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"8YUv3fEYnuOg","executionInfo":{"status":"ok","timestamp":1630475134445,"user_tz":240,"elapsed":18,"user":{"displayName":"Yifu Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnOnAIqYrrfdQ8fUqr0PeOTkp8J-Q2Z4bfbL1P=s64","userId":"02816651394149968559"}},"outputId":"a14b0f0f-9118-44ca-9773-d224b930ed6c"},"source":["#########################        AUXILARY CODE        ######################### \n","def frequency_count(train_data, train_label):\n","    word_freq = {}\n","    for phrase, label in zip(train_data, train_label):\n","        for word in phrase.lower().split(\" \"):\n","          if word not in word_freq:\n","            word_freq[word]=[1,label]\n","          else:\n","            word_freq[word][0] += 1\n","            word_freq[word][1] += label\n","    return word_freq\n","\n","word_freq = frequency_count(train_data, train_label)\n","#########################      END AUXILIARY CODE      #########################\n","\n","def sentiment_analysis(phrase):\n","    \"\"\"\n","    sentiment_analysis function determines whether a phrase is positive (1) or negative (-1).\n","\n","    :param1(string) phrase: a single phrase in the format of string\n","    :return(int)          : 1 if the phrase is postive or -1 if the phrase is negative\n","    \"\"\" \n","    #########################        YOUR CODE        ######################### \n","    score = sum([word_freq[word][1]/word_freq[word][0] for word in phrase.lower().split(\" \")\\\n","                 if word in word_freq])/len(phrase.split(\" \"))\n","    return 1 if score > 0 else -1   \n","    #########################      END YOUR CODE      ######################### \n","\n","\n","def evaluate(func, data, label):\n","    score = 0\n","    for x, y in zip(data, label):\n","        score += (func(x) == y)\n","    return score/len(data)\n","\n","train_acc = evaluate(sentiment_analysis, train_data, train_label)\n","print(f\"Your method has a training accuracy of {train_acc*100}%\")"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Your method has a training accuracy of 99.5%\n"]}]},{"cell_type":"markdown","metadata":{"id":"asx1KUZPzLHp"},"source":["## 5. Evaluate (10/100 points)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"U-uSwJ-bwSr6","executionInfo":{"status":"ok","timestamp":1630475134446,"user_tz":240,"elapsed":14,"user":{"displayName":"Yifu Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnOnAIqYrrfdQ8fUqr0PeOTkp8J-Q2Z4bfbL1P=s64","userId":"02816651394149968559"}},"outputId":"e6c63e08-951e-4082-c457-4574a6abebd7"},"source":["import sys\n","sys.path.append(dir_root)\n","from top_classified_file import super_secret_function\n","\n","test_dir = os.path.join(dir_root, 'test.npy')\n","test_acc = super_secret_function(test_dir, sentiment_analysis)\n","\n","print(f\"Your method has a test accuracy of {test_acc*100}%\")"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Your method has a test accuracy of 72.0%\n"]}]},{"cell_type":"markdown","metadata":{"id":"HVLT3FmezNLF"},"source":["## 6. (Optional) Did you notice something interesting?"]},{"cell_type":"markdown","metadata":{"id":"zh4KPrLtzRCT"},"source":["1. Yes, I think it is because we optimize the model for training dataset not testing dataset.\n","2. No, without package help, the simplest method I can think of is word frequency.\n","3. I met a `Keyerror: \"infused\"` when evaluating testing dataset. The mistake i made is that I forgot to add a condition to check whether a word in testing pharse is in my dictionary `word_freq`. This cause an error when word in testing pharse never appear in training dataset pharses. So I add the condition `if word in word_freq` when computing sentimental score"]}]}